import os
import cv2
import numpy as np
from PIL import Image
from tqdm import tqdm
from sklearn.cluster import KMeans
import torch
import open_clip
import tempfile
import requests
import asyncio
import cloudinary.uploader
from datetime import datetime, timezone
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
# Th√™m sys.path ƒë·ªÉ import database connection
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from database.connection import db
# ============================
# Config
# ============================
BASE_DIR = r"D:\KLCN\backend_app\assets"
EMBEDDINGS_NPY = os.path.join(BASE_DIR, "cached_frame_embs_synced.npy")
KMEANS_DIR = os.path.join(BASE_DIR, "kmeans") # Th∆∞ m·ª•c ƒë·ªÉ l∆∞u bi·ªÉu ƒë·ªì
# T√™n c√°c collection trong MongoDB
VIDEOS_COLLECTION = "videos"
FRAMES_COLLECTION = "frames"

# C√°c tham s·ªë x·ª≠ l√Ω
SAMPLE_RATE = 1.0
K = 30
BATCH_SIZE = 16
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
# ============================
# Init CLIP model
# ============================
print("Initializing CLIP model...")
clip_model, _, clip_preprocess = open_clip.create_model_and_transforms(
    "ViT-L-14",
    pretrained="openai",
    quick_gelu=True  # Add this parameter
)
clip_model = clip_model.to(DEVICE).eval()
print("CLIP model loaded.")
# ============================
# Cloud & Helper Functions
# (C√°c h√†m n√†y kh√¥ng thay ƒë·ªïi)
# ============================
def log(msg):
    print(f"[LOG] {msg}")

def download_video_from_url(video_url, save_path):
    # ... (Gi·ªØ nguy√™n logic download)
    try:
        print(f"üì• ƒêang t·∫£i video t·ª´ {video_url}...")
        with requests.get(video_url, stream=True, timeout=60) as r:
            r.raise_for_status()
            with open(save_path, 'wb') as f:
                for chunk in r.iter_content(chunk_size=8192): f.write(chunk)
        print(f"‚úÖ T·∫£i video th√†nh c√¥ng: {save_path}")
        return save_path
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫£i video {video_url}: {e}")
        return None

async def upload_to_cloud(local_path, file_name):
    # ... (Gi·ªØ nguy√™n logic upload)
    def _upload():
        return cloudinary.uploader.upload(local_path, resource_type="image", folder="frames")
    try:
        result = await asyncio.to_thread(_upload)
        return result.get("secure_url")
    except Exception as e:
        print(f"‚ùå L·ªói khi upload {file_name} l√™n Cloudinary: {e}")
        return None

# ============================
# KMeans Visualization
# ============================
def plot_kmeans(features, labels, video_id, kmeans=None, selected_indices=None, timestamps=None):
    if len(features) < 2:
        return

    pca = PCA(n_components=2)
    reduced = pca.fit_transform(features)

    h = .02
    x_min, x_max = reduced[:, 0].min() - 1, reduced[:, 0].max() + 1
    y_min, y_max = reduced[:, 1].min() - 1, reduced[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))

    if kmeans is not None:
        Z = kmeans.predict(pca.inverse_transform(np.c_[xx.ravel(), yy.ravel()]))
        Z = Z.reshape(xx.shape)
        plt.contourf(xx, yy, Z, cmap="tab20", alpha=0.15)

    plt.scatter(reduced[:, 0], reduced[:, 1], c=labels,
                s=25, cmap="tab20", edgecolor='k', alpha=0.8)

    if kmeans is not None:
        centers_2d = pca.transform(kmeans.cluster_centers_)
        plt.scatter(centers_2d[:, 0], centers_2d[:, 1],
                    marker='X', c='red', s=120, label='Cluster centers')

    for i in range(kmeans.n_clusters if kmeans else len(np.unique(labels))):
        points = reduced[labels == i]
        if len(points) > 2:
            cov = np.cov(points, rowvar=False)
            vals, vecs = np.linalg.eigh(cov)
            order = vals.argsort()[::-1]
            vals, vecs = vals[order], vecs[:, order]
            theta = np.degrees(np.arctan2(*vecs[:, 0][::-1]))
            width, height = 2.5 * np.sqrt(vals)
            ellip = plt.matplotlib.patches.Ellipse(xy=np.mean(points, axis=0),
                                                   width=width, height=height,
                                                   angle=theta,
                                                   edgecolor='gray', facecolor='none',
                                                   linestyle='--', linewidth=1.2, alpha=0.8)
            plt.gca().add_artist(ellip)
            cx, cy = np.mean(points, axis=0)
            plt.text(cx, cy, f"{i+1}", fontsize=9, color='darkred',
                     ha='center', va='center', weight='bold', alpha=0.9)

    if selected_indices is not None and len(selected_indices) > 0:
        plt.scatter(reduced[selected_indices, 0],
                    reduced[selected_indices, 1],
                    s=140, facecolors='none', edgecolors='black',
                    linewidths=2.5, label='Keyframes')
        if timestamps is not None:
            for idx in selected_indices:
                if idx < len(timestamps):
                    ts = timestamps[idx]
                    x, y = reduced[idx, 0], reduced[idx, 1]
                    plt.text(x + 0.05, y + 0.05, ts,
                             fontsize=7, color='darkblue',
                             weight='bold', alpha=0.9)

    k_val = kmeans.n_clusters if kmeans else len(np.unique(labels))
    n_keyframes = len(selected_indices) if selected_indices is not None else 0
    plt.title(
        f"{video_id}\nT·ªïng frame: {len(features)} | C·ª•m: {k_val} | Frame sau gom: {n_keyframes}",
        fontsize=11, weight='bold', color='darkblue'
    )
    plt.legend(loc='best', fontsize=8)
    plt.xlabel("PCA Dimension 1")
    plt.ylabel("PCA Dimension 2")
    plt.grid(True, linestyle='--', alpha=0.3)
    plt.tight_layout()

    os.makedirs(KMEANS_DIR, exist_ok=True)
    save_path = os.path.join(KMEANS_DIR, f"{video_id}_kmeans.png")
    plt.savefig(save_path, dpi=300)
    plt.close()
    log(f"üìä ƒê√£ l∆∞u bi·ªÉu ƒë·ªì KMeans cho {video_id} t·∫°i {save_path}")
# ============================
# Ch·ªçn keyframe b·∫±ng KMeans
# ============================
def select_keyframes(frame_features, k=30):
    k = min(k, len(frame_features))
    if k <= 0:
        return [], None, None # Tr·∫£ v·ªÅ None n·∫øu kh√¥ng x·ª≠ l√Ω

    kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')
    labels = kmeans.fit_predict(frame_features)
    
    selected_indices = []
    for i in range(k):
        cluster_indices = np.where(labels == i)[0]
        if len(cluster_indices) == 0:
            continue
        center = kmeans.cluster_centers_[i]
        points_in_cluster = frame_features[cluster_indices]
        dists = np.linalg.norm(points_in_cluster - center, axis=1)
        best_idx_in_cluster = np.argmin(dists)
        original_idx = cluster_indices[best_idx_in_cluster]
        selected_indices.append(original_idx)
        
    # Tr·∫£ v·ªÅ th√™m 'labels' v√† 'kmeans' ƒë·ªÉ d√πng cho vi·ªác v·∫Ω bi·ªÉu ƒë·ªì
    return sorted(selected_indices), labels, kmeans

def encode_frames(paths, batch_size=BATCH_SIZE):
    embs = []
    with torch.no_grad():
        for i in tqdm(range(0, len(paths), batch_size), desc="ü§ñ Encoding Frames"):
            batch = paths[i:i+batch_size]
            imgs = []
            for p in batch:
                try:
                    img = Image.open(p).convert("RGB")
                    imgs.append(clip_preprocess(img))
                except Exception as e:
                    log(f"‚ö†Ô∏è L·ªói load ·∫£nh {p}: {e}")
            if imgs:
                tensor = torch.stack(imgs).to(DEVICE)
                feats = clip_model.encode_image(tensor)
                feats = feats / feats.norm(dim=-1, keepdim=True)
                embs.append(feats.cpu().numpy())
    return np.concatenate(embs, axis=0) if embs else np.empty((0, 768), dtype=np.float32)

# ============================
# << CORE LOGIC >> Pipeline x·ª≠ l√Ω ch√≠nh cho m·ªôt video
# ============================
async def process_new_video(video_doc: dict):
    """
    H√†m x·ª≠ l√Ω ho√†n ch·ªânh cho m·ªôt video: t·∫£i v·ªÅ, ph√¢n t√≠ch, v√† c·∫≠p nh·∫≠t k·∫øt qu·∫£.
    """
    video_id = video_doc["_id"]
    video_url = video_doc["url"]
    video_title = video_doc["title"]
    log(f"üé¨ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω video: {video_title} (ID: {video_id})")

    try:
        # S·ª≠ d·ª•ng th∆∞ m·ª•c t·∫°m ƒë·ªÉ ƒë·∫£m b·∫£o c√°c file ƒë∆∞·ª£c d·ªçn d·∫πp s·∫°ch s·∫Ω
        with tempfile.TemporaryDirectory() as temp_dir:
            local_video_path = os.path.join(temp_dir, f"{video_title}.mp4")

            # 1. T·∫£i video t·ª´ cloud v·ªÅ m√°y t·∫°m
            if not download_video_from_url(video_url, local_video_path):
                raise Exception("Kh√¥ng th·ªÉ t·∫£i video t·ª´ cloud.")

            # 2. C·∫Øt video th√†nh c√°c frame th√¥ (logic t·ª´ file g·ªëc)
            cap = cv2.VideoCapture(local_video_path)
            fps = cap.get(cv2.CAP_PROP_FPS) or 30
            frame_interval = int(fps * SAMPLE_RATE)
            
            temp_frame_paths, timestamps = [], []
            frame_count = 0
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                if frame_count % frame_interval == 0:
                    temp_path = os.path.join(temp_dir, f"frame_{frame_count:06d}.jpg")
                    cv2.imwrite(temp_path, frame)
                    temp_frame_paths.append(temp_path)
                    timestamps.append(f"{frame_count / fps:.2f}s")
                frame_count += 1
            cap.release()
            
            if not temp_frame_paths:
                log(f"‚ö†Ô∏è Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c frame n√†o t·ª´ {video_id}.")
                raise Exception("Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c frame.")
            log(f"üéûÔ∏è  Tr√≠ch xu·∫•t ƒë∆∞·ª£c {len(temp_frame_paths)} frame th√¥.")

            # 3. Encode t·∫•t c·∫£ frame th√¥ b·∫±ng CLIP
            all_frame_embs = encode_frames(temp_frame_paths)
            if all_frame_embs.shape[0] == 0:
                raise Exception("Kh√¥ng encode ƒë∆∞·ª£c frame n√†o.")

            # 4. D√πng K-Means ƒë·ªÉ ch·ªçn ra c√°c keyframe
            keyframe_indices, labels, kmeans_model = select_keyframes(all_frame_embs, k=K) # S·ª≠a ·ªü ƒë√¢y
            log(f"‚ú® Ch·ªçn ƒë∆∞·ª£c {len(keyframe_indices)} keyframes b·∫±ng K-Means.")

            # Th√™m ngay sau ƒë√≥:
            # 4.1. V·∫Ω v√† l∆∞u bi·ªÉu ƒë·ªì K-Means
            if kmeans_model: # Ch·ªâ v·∫Ω n·∫øu K-Means ch·∫°y th√†nh c√¥ng
                # L√†m s·∫°ch title ƒë·ªÉ d√πng l√†m t√™n file an to√†n
                safe_filename = "".join(c for c in video_title if c.isalnum() or c in (' ')).rstrip()
                safe_filename = safe_filename.replace(' ')

                plot_kmeans(
                    features=all_frame_embs,
                    labels=labels,
                    video_id=safe_filename, # << S·ª¨ D·ª§NG TITLE ·ªû ƒê√ÇY
                    kmeans=kmeans_model,
                    selected_indices=keyframe_indices,
                    timestamps=timestamps
                )

            # 5. Upload c√°c keyframe ƒë√£ ch·ªçn l√™n cloud
            upload_tasks = []
            for idx in keyframe_indices:
                local_path = temp_frame_paths[idx]
                file_name = os.path.basename(local_path)
                upload_tasks.append(upload_to_cloud(local_path, file_name))
            
            # Ch·∫°y c√°c t√°c v·ª• upload song song ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô
            cloud_urls = await asyncio.gather(*upload_tasks)

            keyframe_metadata_list = []
            keyframe_embeddings_list = []
            for i, idx in enumerate(keyframe_indices):
                cloud_url = cloud_urls[i]
                if cloud_url:
                    keyframe_metadata_list.append({
                        "frame_id": f"{video_id}_{idx:06d}",
                        "video_id": video_id,
                        "path": cloud_url,
                        "timestamp": timestamps[idx],
                        "video_path": video_url,
                    })
                    keyframe_embeddings_list.append(all_frame_embs[idx])

        # H·∫øt kh·ªëi `with`, th∆∞ m·ª•c t·∫°m v√† c√°c file b√™n trong s·∫Ω t·ª± ƒë·ªông b·ªã x√≥a

        # 6. C·∫≠p nh·∫≠t MongoDB v·ªõi c√°c keyframe m·ªõi
        if keyframe_metadata_list:
            log(f"üíæ ƒêang ghi {len(keyframe_metadata_list)} keyframes v√†o MongoDB...")
            frames_collection = db[FRAMES_COLLECTION]
            await frames_collection.insert_many(keyframe_metadata_list)
            log("‚úÖ Ghi keyframes v√†o MongoDB th√†nh c√¥ng.")

        # 7. C·∫≠p nh·∫≠t file embedding .npy
        if keyframe_embeddings_list:
            new_embs = np.array(keyframe_embeddings_list)
            log(f"üíæ ƒêang c·∫≠p nh·∫≠t file embedding: {EMBEDDINGS_NPY}")
            if os.path.exists(EMBEDDINGS_NPY):
                old_embs = np.load(EMBEDDINGS_NPY)
                all_embs = np.concatenate([old_embs, new_embs], axis=0)
            else:
                all_embs = new_embs
            np.save(EMBEDDINGS_NPY, all_embs)
            log(f"‚úÖ C·∫≠p nh·∫≠t file embedding th√†nh c√¥ng, t·ªïng s·ªë vector: {len(all_embs)}")

        # 8. ƒê√°nh d·∫•u video ƒë√£ x·ª≠ l√Ω th√†nh c√¥ng
        videos_collection = db[VIDEOS_COLLECTION]
        await videos_collection.update_one(
            {"_id": video_id},
            {"$set": {
                "status_video": "COMPLETED",
                "processed_at": datetime.now(timezone.utc)
            }}
        )
        log(f"üèÅ Ho√†n t·∫•t x·ª≠ l√Ω video: {video_id}")

    except Exception as e:
        log(f"‚ùå L·ªói nghi√™m tr·ªçng khi x·ª≠ l√Ω {video_id}: {e}")
        # ƒê√°nh d·∫•u video x·ª≠ l√Ω th·∫•t b·∫°i
        videos_collection = db[VIDEOS_COLLECTION]
        await videos_collection.update_one(
            {"_id": video_id},
            {"$set": {
                "status_video": "FAILED",
                "error_message": str(e)
            }}
        )
# ============================
# << WORKER LOOP >> V√≤ng l·∫∑p ch√≠nh c·ªßa worker
# ============================
async def main_worker_loop():
    log("üöÄ Worker x·ª≠ l√Ω video ƒë√£ kh·ªüi ƒë·ªông, ƒëang t√¨m ki·∫øm c√°c video PENDING...")
    videos_collection = db[VIDEOS_COLLECTION]
    
    while True:
        try:
            # T√¨m m·ªôt video PENDING v√† c·∫≠p nh·∫≠t ngay th√†nh PROCESSING
            # Thao t√°c n√†y ƒë·∫£m b·∫£o kh√¥ng worker n√†o kh√°c l·∫•y c√πng video
            pending_video = await videos_collection.find_one_and_update(
                {"status_video": "PENDING"},
                {"$set": {"status_video": "PROCESSING", "processed_at": datetime.now(timezone.utc)}}
            )

            if pending_video:
                # N·∫øu t√¨m th·∫•y, b·∫Øt ƒë·∫ßu x·ª≠ l√Ω
                await process_new_video(pending_video)
            else:
                # N·∫øu kh√¥ng c√≥ video n√†o, ƒë·ª£i 30 gi√¢y r·ªìi t√¨m l·∫°i
                log("...Kh√¥ng c√≥ video m·ªõi. T·∫°m ngh·ªâ 30 gi√¢y...")
                await asyncio.sleep(30)

        except Exception as e:
            log(f"üî• L·ªói trong v√≤ng l·∫∑p ch√≠nh c·ªßa worker: {e}")
            await asyncio.sleep(15) # ƒê·ª£i l√¢u h∆°n n·∫øu c√≥ l·ªói nghi√™m tr·ªçng

#main            
#if __name__ == "__main__":
#    asyncio.run(main_worker_loop())