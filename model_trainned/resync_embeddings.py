import os
import numpy as np
from PIL import Image
from tqdm import tqdm
import torch
import open_clip
import requests
from io import BytesIO
import asyncio

# Th√™m sys.path ƒë·ªÉ import database connection
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.connection import db

# ============================
# Config
# ============================
BASE_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'assets')
# T·∫†O RA M·ªòT FILE .npy M·ªöI ƒê·ªÇ TR√ÅNH GHI ƒê√à L√äN FILE C≈® NGAY L·∫¨P T·ª®C
NEW_EMBEDDINGS_NPY = os.path.join(BASE_DIR, "cached_frame_embs_RESYNCED.npy")

FRAMES_COLLECTION = "frames"
BATCH_SIZE = 32 # X·ª≠ l√Ω theo l√¥ ƒë·ªÉ t·∫≠n d·ª•ng GPU
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ============================
# Main Logic
# ============================
async def resync_embeddings_from_db():
    print("--- B·∫Øt ƒë·∫ßu qu√° tr√¨nh ƒë·ªìng b·ªô l·∫°i embeddings t·ª´ MongoDB v√† Cloud ---")
    
    # 1. Kh·ªüi t·∫°o model CLIP
    print("Initializing CLIP model...")
    clip_model, _, clip_preprocess = open_clip.create_model_and_transforms(
        "ViT-L-14", pretrained="openai", quick_gelu=True
    )
    clip_model = clip_model.to(DEVICE).eval()
    print("CLIP model loaded.")

    # 2. L·∫•y danh s√°ch frame ƒë√£ ƒë∆∞·ª£c s·∫Øp x·∫øp t·ª´ MongoDB
    print(f"Fetching sorted frame documents from '{FRAMES_COLLECTION}' collection...")
    frames_collection = db[FRAMES_COLLECTION]
    
    # S·∫Øp x·∫øp theo video_id v√† frame_id ƒë·ªÉ c√≥ m·ªôt tr·∫≠t t·ª± nh·∫•t qu√°n
    cursor = frames_collection.find({}, {"path": 1}).sort([
        ("video_id", 1), 
        ("frame_id", 1)
    ])
    
    # L·∫•y to√†n b·ªô document v√†o m·ªôt danh s√°ch
    sorted_frames = await cursor.to_list(length=None)
    
    if not sorted_frames:
        print("‚ùå Collection 'frames' r·ªóng. Kh√¥ng c√≥ g√¨ ƒë·ªÉ x·ª≠ l√Ω.")
        return
        
    print(f"‚úÖ T√¨m th·∫•y {len(sorted_frames)} frames c·∫ßn x·ª≠ l√Ω.")

    # 3. T·∫£i ·∫£nh, encode l·∫°i v√† l∆∞u v√†o danh s√°ch
    all_new_embeddings = []
    
    pbar = tqdm(total=len(sorted_frames), desc="üñºÔ∏è  Re-encoding frames")

    for i in range(0, len(sorted_frames), BATCH_SIZE):
        batch_docs = sorted_frames[i : i + BATCH_SIZE]
        image_tensors = []
        
        for doc in batch_docs:
            image_url = doc.get("path")
            if not image_url:
                pbar.update(1)
                continue
                
            try:
                # T·∫£i ·∫£nh t·ª´ cloud
                response = requests.get(image_url, timeout=100)
                response.raise_for_status()
                image = Image.open(BytesIO(response.content)).convert("RGB")
                
                # Preprocess ·∫£nh v√† th√™m v√†o batch
                image_tensors.append(clip_preprocess(image))
            except Exception as e:
                print(f"\n‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω ·∫£nh {image_url}: {e}")
        
        if image_tensors:
            # T·∫°o tensor t·ª´ batch ·∫£nh
            batch_tensor = torch.stack(image_tensors).to(DEVICE)
            
            # Encode c·∫£ batch trong m·ªôt l·∫ßn
            with torch.no_grad():
                feats = clip_model.encode_image(batch_tensor)
                feats /= feats.norm(dim=-1, keepdim=True)
                all_new_embeddings.append(feats.cpu().numpy())
        
        pbar.update(len(batch_docs))
        
    pbar.close()

    if not all_new_embeddings:
        print("‚ùå Kh√¥ng encode ƒë∆∞·ª£c embedding n√†o.")
        return

    # 4. N·ªëi t·∫•t c·∫£ c√°c batch embedding v√† l∆∞u file .npy m·ªõi
    final_embeddings = np.concatenate(all_new_embeddings, axis=0)
    print(f"\nüíæ ƒêang l∆∞u file embedding ƒë√£ ƒë·ªìng b·ªô t·∫°i: {NEW_EMBEDDINGS_NPY}")
    np.save(NEW_EMBEDDINGS_NPY, final_embeddings)
    
    print("\nüéâ HO√ÄN T·∫§T! Qu√° tr√¨nh ƒë·ªìng b·ªô ƒë√£ xong.")
    print(f"   - T·ªïng s·ªë embedding ƒë√£ t·∫°o: {len(final_embeddings)}")
    print("   - B·∫°n c√≥ th·ªÉ ƒë·ªïi t√™n file 'cached_frame_embs_RESYNCED.npy' th√†nh 'cached_frame_embs_synced.npy' ƒë·ªÉ h·ªá th·ªëng s·ª≠ d·ª•ng.")


if __name__ == "__main__":
    # C·∫ßn c√†i ƒë·∫∑t requests: pip install requests
    asyncio.run(resync_embeddings_from_db())

# note: ·∫£nh l·ªói truy c·∫≠p c·∫ßn x·ª≠ l√≠
#//res.cloudinary.com/dbdty9p1v/image/upload/v1760703569/frames/v0zbmq4dhhzqn464kbpl.jpg   #6432
